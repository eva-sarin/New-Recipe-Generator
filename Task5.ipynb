{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Task5.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "u7p_fEaPxuty",
        "colab_type": "text"
      },
      "source": [
        "# Using Natural Language Processing to Generate New Recipes in Python\n",
        "## Task 5: HuggingFace Integration and Model Training on Google Colab\n",
        "\n",
        "I recommend this task to be optional. If you'd like to do it, you will need to have (or create) a Google account for [Google Drive](drive.google.com) and [Google Colab](colab.research.google.com)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "n_1h_isKxutz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6b2a512-33a3-47c8-e8dd-ade844b0516b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3_EKYVyGiE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "1b361810-94ed-4659-def0-db5f3780ef44"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers;\n",
        "!cd transformers; pip3 install ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 41076 (delta 7), reused 15 (delta 1), pack-reused 41045\u001b[K\n",
            "Receiving objects: 100% (41076/41076), 29.74 MiB | 29.97 MiB/s, done.\n",
            "Resolving deltas: 100% (28477/28477), done.\n",
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.1.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.1.0) (0.16.0)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.1.0-cp36-none-any.whl size=962760 sha256=0a661552a9d46fbcfef84b83e570e4c9b577381e85c9c239e4fb9c38de678f3c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4o04j7li/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a880460060563c310fe8b311d25e241393cdf620ab3491260ca63ec62d129842\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2xD9nKgHKHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "567628d3-706e-4614-81fc-b75e02a91d74"
      },
      "source": [
        "!scp gdrive\\My/ Drive/dataset_train.txt dataset_train.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset_train.txt: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elYsuVoFH3hg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "4eb4d5e6-c50f-4335-fe84-dce200e4b184"
      },
      "source": [
        "!bash run_experiments.sh"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-12 16:22:26.698449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "09/12/2020 16:22:28 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "09/12/2020 16:22:28 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='experiments/epochs_10', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluate_during_training=False, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Sep12_16-22-28_2ff5b75f08f9', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1, run_name=None, disable_tqdm=False, remove_unused_columns=True)\n",
            "09/12/2020 16:22:29 - INFO - filelock -   Lock 140670686667552 acquired on /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.7c30f0c070132208a64285a2dce903c733f1db6a70d16d1fac1663fd79b640b7.lock\n",
            "Downloading: 100% 762/762 [00:00<00:00, 668kB/s]\n",
            "09/12/2020 16:22:29 - INFO - filelock -   Lock 140670686667552 released on /root/.cache/torch/transformers/eb0f77b3f095880586731f57e2fe19060d71d1036ef8daf727bd97a17fb66a43.7c30f0c070132208a64285a2dce903c733f1db6a70d16d1fac1663fd79b640b7.lock\n",
            "09/12/2020 16:22:30 - INFO - filelock -   Lock 140670686667552 acquired on /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 2.68MB/s]\n",
            "09/12/2020 16:22:30 - INFO - filelock -   Lock 140670686667552 released on /root/.cache/torch/transformers/71cc2431cf0b5bbe7a23601a808ed322c90251c8261b46f04970140a3c2c1cb4.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "09/12/2020 16:22:31 - INFO - filelock -   Lock 140670686667552 acquired on /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 1.86MB/s]\n",
            "09/12/2020 16:22:31 - INFO - filelock -   Lock 140670686667552 released on /root/.cache/torch/transformers/4faf7afb02a1ea7d2944e9ba7a175c7b8de4957cdbae75cd5ddffc7c7643ebbc.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:779: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n",
            "09/12/2020 16:22:32 - INFO - filelock -   Lock 140670287539000 acquired on /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c.lock\n",
            "Downloading: 100% 353M/353M [00:09<00:00, 35.5MB/s]\n",
            "09/12/2020 16:22:42 - INFO - filelock -   Lock 140670287539000 released on /root/.cache/torch/transformers/cd250f30004d0dee11ff1af311bd3facb6f38739fd870b9c8aa9321333a550be.ffe4c53a2a410b15148cf4170cc408d2d2f98adeecdde146ef8e71843039ff3c.lock\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1321: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n",
            "Traceback (most recent call last):\n",
            "  File \"run_lm_finetuning.py\", line 296, in <module>\n",
            "    main()\n",
            "  File \"run_lm_finetuning.py\", line 232, in main\n",
            "    train_dataset = get_dataset(data_args, tokenizer=tokenizer) if training_args.do_train else None\n",
            "  File \"run_lm_finetuning.py\", line 134, in get_dataset\n",
            "    tokenizer=tokenizer, file_path=file_path, block_size=args.block_size, overwrite_cache=args.overwrite_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/data/datasets/language_modeling.py\", line 33, in __init__\n",
            "    assert os.path.isfile(file_path), f\"Input file path {file_path} not found\"\n",
            "AssertionError: Input file path dataset.txt not found\n",
            "run_experiments.sh: line 14: commandN: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV7yA_KNH-5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}